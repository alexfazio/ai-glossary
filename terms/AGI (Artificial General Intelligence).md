---
share: true
---

In broad terms, AGI typically means artificial intelligence that matches (or outmatches) humans on a range of tasks. But specifics about what counts as human-like, what tasks, and how many all tend to get waved away: AGI is AI, but better. AGI, or [artificial general intelligence](https://www.technologyreview.com/2020/10/15/1010461/artificial-general-intelligence-robots-ai-agi-deepmind-google-openai/), is one of the hottest topics in tech today. It’s also one of the most controversial. A big part of the problem is that few people agree on what the term even means. [^3]

Three things stand out from the current visions for Artificial General Intelligence (AGI): a human-like ability to generalize, a superhuman ability to self-improve at an exponential rate, and a significant amount of wishful thinking. When people discuss AGI, they typically refer to human-like abilities. This causes the targets of the search for AGI to constantly shift. Defining human-like abilities is challenging: What exactly do people mean when they refer to human-like artificial intelligence? Is it human-like in the way you and I are, or human-like in the way Lazarus Long is? [^5] 

Artificial general intelligence (AGI) -- often referred to as "strong AI," "full AI," "human-level AI" or "general intelligent action" -- represents a significant future leap in the field of artificial intelligence. Unlike [Narrow AI](../Narrow%20AI.md), which is tailored for specific tasks, such as [detecting product flaws](https://techcrunch.com/2024/03/12/axion-rays-ai-attempts-to-detect-product-flaws-to-prevent-recalls/), [summarizing the news](https://techcrunch.com/2024/02/29/former-twitter-engineers-are-building-particle-an-ai-powered-news-reader/), or [building you a website](https://techcrunch.com/2024/02/22/10web-armenia/), AGI will be able to perform a broad spectrum of cognitive tasks at or above human levels. [^1]

The concept raises existential questions about humanity's role in and control of a future where machines can outthink, outlearn and outperform humans in virtually every domain. [^1]

The core of this concern lies in the unpredictability of AGI's decision-making processes and objectives, which might not align with human values or priorities (a concept [explored in-depth in science fiction since at least the 1940s](https://en.wikipedia.org/wiki/Three_Laws_of_Robotics)). There's concern that once AGI reaches a certain level of autonomy and capability, it might become impossible to contain or control, leading to scenarios where its actions cannot be predicted or reversed. [^1]

OpenAI, the research organization behind ChatGPT, has acknowledged that the development of Artificial General Intelligence (AGI) and superintelligence could potentially replace human labor. According to their website, AGI is defined as a system that surpasses human performance in most economically valuable work. And this is just AGI, not even considering superintelligence ([ASI](../ASI%20(Artificial%20Superintelligence).md)). [^2]

### Footnotes

[^1]: https://techcrunch.com/2024/03/19/agi-and-hallucinations/
[^2]: https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/
[^3]: https://www.technologyreview.com/2023/11/16/1083498/google-deepmind-what-is-artificial-general-intelligence-agi/
[^5]: https://www.technologyreview.com/2020/10/15/1010461/artificial-general-intelligence-robots-ai-agi-deepmind-google-openai/