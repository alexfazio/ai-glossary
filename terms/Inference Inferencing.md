---
share: true
---

"Inference" is the term for actually using the model to make predictions. When people discuss inference speed, they're usually concerned about two things: The prompt processing speed, and the generation speed.
Both of these can be measured in "tokens per second", but the numbers for each tend to be different due to how batching works (naturally, it's a lot faster to evaluate 500 tokens at once compared to evaluating 1 token at a time, which is what is happening during the generation process).
Inference Engine: A component of a [expert] system that applies logical rules to the knowledge base to deduce new or additional information.

### Related Articles

### Citations
