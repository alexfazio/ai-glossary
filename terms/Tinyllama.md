---
share: true
---

A project to pre-train a 1.1B Llama model on 3 trillion tokens.

### Related Articles

### Citations
