---
share: true
---

‘Trustworthy AI’ is a framework developed by [Deloitte](https://en.m.wikipedia.org/wiki/Deloitte) to help manage AI risk. [^1]

Deloitte’s Trustworthy AI framework introduces six key dimensions that, when considered collectively in the design, development, deployment, and operational phases of AI system implementation, can help safeguard ethics and build a trustworthy AI strategy. [^1]

The Trustworthy AI framework is designed to help companies identify and mitigate potential risks related to AI ethics at every stage of the AI lifecycle. Here’s a closer look at each of the framework’s six dimensions. [^1]


![Pasted image 20240416220310](./Pasted%20image%2020240416220310.png)


1. **Fair, not biased** - How AI makes decisions must be open to inspection and fully explainable
	For AI to be trustworthy, all participants have a right to understand how their data is being used and how the AI is making decisions.
2. **Transparent and explainable** - Clear policies must establish accountability for AI output
	Trustworthy AI systems need to include policies that clearly establish who is responsible and accountable for their output.
3. **Responsible and accountable** - Clear policies must establish accountability for AI output
	Trustworthy AI systems need to include policies that clearly establish who is responsible and accountable for their output.
4. **Robust and reliable** - AI must be as reliable as traditional systems and consistent in all conditions
	In order for AI to achieve widespread adoption, it must be at least as robust and reliable as the traditional systems, processes, and people it is augmenting or replacing.
5. **Respectful of privacy** - AI must comply with regulations and only use data as agreed
	Privacy is a critical issue for all types of data systems, but it is especially critical for AI since the sophisticated insights generated by AI systems often stem from data that is more detailed and personal.
6. **Safe and secure** - AI must be protected from risks like hacking that could harm people or data
	To be trustworthy, AI must be protected from cybersecurity risks that might lead to physical and/or digital harm.

### Footnotes

[^1]: https://www.technologyreview.com/2020/03/25/950291/trustworthy-ai-is-a-framework-to-help-manage-unique-risk/